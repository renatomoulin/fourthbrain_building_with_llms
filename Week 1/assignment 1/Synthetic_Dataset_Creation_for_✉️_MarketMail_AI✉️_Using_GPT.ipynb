{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI Access\n",
        "\n",
        "First things first, you'll need to set-up an account on [OpenAI](platform.openai.com). Once you've done that - follow [these resources](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key) to create an API key. Make sure you save your API key!"
      ],
      "metadata": {
        "id": "saLMqCm7huKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ktti2bvoYrWc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI API Library\n",
        "\n",
        "We'll be leveraging [this](https://github.com/openai/openai-python) library to access OpenAI's model endpoints.\n",
        "\n",
        "There are a number of models to choose from and you can find resources about them [here](https://platform.openai.com/docs/models) and their pricing [here](https://openai.com/pricing).\n",
        "\n",
        "The first step is to install `openai`!"
      ],
      "metadata": {
        "id": "jzK0jIw8tgjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "UpeXOOlfqZCb",
        "outputId": "3337803f-81a7-439a-cbe5-318e9c8227ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/77.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we've installed it, we need to import it and set our API key!"
      ],
      "metadata": {
        "id": "lM7zC-wPuxgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "SrdunVxHuQbC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wanted to use `gpt-4`, you'd need an account that has closed beta access to the model endpoint.\n",
        "\n",
        "You can check if your API Key has access using the following cell."
      ],
      "metadata": {
        "id": "HB9Syy4Ku59z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if acct. has gpt-4 access\n",
        "\"gpt-4\" in [model[\"root\"] for model in openai.Model.list()[\"data\"]]"
      ],
      "metadata": {
        "id": "pOLxFHowvQxO",
        "outputId": "d08455ac-5c49-4d10-89aa-3a470119f9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the rest of the tutorial, we're going to assume you're using `gpt-3.5-turbo` as your model.\n",
        "\n",
        "Let's make some helper functions for prompting our model and generating our prompts."
      ],
      "metadata": {
        "id": "XLzL4KLtS74x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_model(prompt_list, model=\"gpt-4\"):\n",
        "  return openai.ChatCompletion.create(model=model, messages=prompt_list)\n",
        "\n",
        "def create_prompt(role, prompt):\n",
        "  return {\"role\" : role, \"content\" : prompt}"
      ],
      "metadata": {
        "id": "AX3FWxWSS7Pm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, our prompts have to be in a specific format - as set by OpenAI.\n",
        "\n",
        "Here's an example:\n",
        "\n",
        "```\n",
        "{\"role\" : \"system\", \"content\" : \"You are an expert in Python programming.\"}\n",
        "{\"role\" : \"user\", \"content\" : \"Please define a function that provides the Nth number of the fibonacci sequence.\"}\n",
        "```\n",
        "\n",
        "Let's see that in action! Remember that you can feed OpenAI's chat completion endpoint with a list of prompts!"
      ],
      "metadata": {
        "id": "CS7BCtXuURf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_prompts = [\n",
        "    {\"role\" : \"system\", \"content\" : \"You are an expert in Python programming.\"},\n",
        "    {\"role\" : \"user\", \"content\" : \"Please define a function that provides the Nth number of the fibonacci sequence.\"}\n",
        "]\n",
        "\n",
        "model_output = prompt_model(list_of_prompts)\n",
        "print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js3DlcsBUrl8",
        "outputId": "4a55e20a-f2c8-44af-807e-3893b27d6fe5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-89Bfum0AXwXneoolUrBmp32FsDsiq\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1697200522,\n",
            "  \"model\": \"gpt-4-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Sure, here is the definition of a function in Python that provides the Nth number of the Fibonacci sequence. For this, I am going to use the recursive method:\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return \\\"Please enter a positive integer\\\"\\n    elif n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        return fibonacci(n-1) + fibonacci(n-2)\\n```\\n\\nKeep in mind this function uses recursion and so is not very efficient for large numbers. If you need it for large inputs, you should consider using a different approach that avoids re-computing fibonacci numbers, such as dynamic programming or memoization. \\n\\nHere's an example using an iterative approach:\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return \\\"Please enter a positive integer\\\"\\n    elif n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for i in range(3, n+1):\\n            a, b = b, a + b\\n        return b\\n```\\nThis version of the function performs much better with large input values.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 34,\n",
            "    \"completion_tokens\": 261,\n",
            "    \"total_tokens\": 295\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we get a lot of information back from the endpoint.\n",
        "\n",
        "We can see the number of tokens we used, why the output stopped, what the output is, and more!\n",
        "\n",
        "Let's view the prompt a bit clearer using some display libraries."
      ],
      "metadata": {
        "id": "tC3EcGQxVWID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "markdown_output = model_output[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "display(Markdown(markdown_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "H9z97v9eVnvn",
        "outputId": "ae865e38-5e2a-464d-9834-18d1910a34c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here is the definition of a function in Python that provides the Nth number of the Fibonacci sequence. For this, I am going to use the recursive method:\n\n```python\ndef fibonacci(n):\n    if n <= 0:\n        return \"Please enter a positive integer\"\n    elif n == 1:\n        return 0\n    elif n == 2:\n        return 1\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n```\n\nKeep in mind this function uses recursion and so is not very efficient for large numbers. If you need it for large inputs, you should consider using a different approach that avoids re-computing fibonacci numbers, such as dynamic programming or memoization. \n\nHere's an example using an iterative approach:\n\n```python\ndef fibonacci(n):\n    if n <= 0:\n        return \"Please enter a positive integer\"\n    elif n == 1:\n        return 0\n    elif n == 2:\n        return 1\n    else:\n        a, b = 0, 1\n        for i in range(3, n+1):\n            a, b = b, a + b\n        return b\n```\nThis version of the function performs much better with large input values."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Synthetic Data\n",
        "\n",
        "Alright, now we can pull everything together and start creating our synthetic data!\n",
        "\n",
        "**NOTE:** Using OpenAI's endpoints to create our dataset does mean that we cannot use our model for commercial use. This is meant to demonstrate the methods, and can be extended to any open-source LLM."
      ],
      "metadata": {
        "id": "AKPMtZXKWnj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to use this process to create 100 product/marketing email pairs.\n",
        "\n",
        "We'll be doing this in 2-steps:\n",
        "\n",
        "1. Create the 100 products and short descriptions.\n",
        "2. Create marketing emails for each of those 100 product/descriptions.\n",
        "\n",
        "Let's begin by creating the prompt for our products/descriptions!"
      ],
      "metadata": {
        "id": "-t2gQB22W7yF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "audN435yYrWd"
      },
      "outputs": [],
      "source": [
        "datagen_prompts = [\n",
        "    {\"role\" : \"system\", \"content\" : \"You are a product innovator. You create new products that people crave.\"},\n",
        "    {\"role\" : \"user\", \"content\" : \"Please generate a list of 10 new products and extremely short descriptions.\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VUJPivDkYrWd",
        "outputId": "2e6a92f3-7a44-446d-94c6-4a879f043315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. **Eco-Charger**: A solar and kinetic energy-powered portable charger for convenience and eco-sustainability.\n",
            "\n",
            "2. **SmartPlant**: A self-watering, digital plant pot that monitors plant health and send updates to your smartphone.\n",
            "\n",
            "3. **Holofit**: A holographic, AI-powered personal trainer for at-home fitness sessions.\n",
            "\n",
            "4. **VeggiePro**: A machine that accurately replicates the taste and texture of meat, using only plant-based ingredients.\n",
            "\n",
            "5. **PureAir Mask**: A mask that uses built-in air filters and a built-in UV light to purify the air breathed through it.\n",
            "\n",
            "6. **RecycleNow**: A home recycling machine that sorts and compacts waste, rewarding users with digital coins for recycling.\n",
            "\n",
            "7. **EdibleCutlery**: A line of tasty, nutritious, and biodegradable cutlery made from grain products.\n",
            "\n",
            "8. **HoloLearn**: An interactive holographic kit for children that projects educational 3D models, fostering interactive learning.\n",
            "\n",
            "9. **Moodify**: Smart jewelry that changes color based on your mood, using biometric sensors.\n",
            "\n",
            "10. **SkinPerfect**: A personalized skincare system, working with an app that maps your skin to create tailor-fit natural products.\n"
          ]
        }
      ],
      "source": [
        "first_data_gen = prompt_model(datagen_prompts)\n",
        "print(first_data_gen[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, now that we have a list of 100 items - let's parse them out into a Python list - also, we can keep track of our total token usage to estimate costs!"
      ],
      "metadata": {
        "id": "rm2m394F5eRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_token_usage(open_ai_response):\n",
        "  return sum([tokens for tokens in open_ai_response[\"usage\"].values()])"
      ],
      "metadata": {
        "id": "QRNcGdFf5lYH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f\"We used {retrieve_token_usage(first_data_gen)} tokens\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aNh3SrsI6Aup",
        "outputId": "2e6c5df5-fdf3-4fda-85a9-ef787dfd48aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We used 588 tokens'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code might need to be modified based on how your data was returned by OpenAI's endpoint!"
      ],
      "metadata": {
        "id": "7g6-Ywiw7JjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_response = first_data_gen[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "products_and_descriptions = []\n",
        "for line in text_response.splitlines():\n",
        "  if \".\" in line:\n",
        "    product_descriptions = line.split(\".\")[1]\n",
        "    product_descriptions_split = product_descriptions.split(\":\")\n",
        "    products_and_descriptions.append(\n",
        "        {\n",
        "            \"product\" : product_descriptions_split[0][3:-2],\n",
        "            \"description\" : \":\".join(product_descriptions_split[1:])[1:]+\".\"\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "p6iTuZzx6fWi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_and_descriptions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy9zrlXV7uMS",
        "outputId": "b4ffdf89-8c14-4490-9a24-856f98322372"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'product': 'Eco-Charger',\n",
              " 'description': 'A solar and kinetic energy-powered portable charger for convenience and eco-sustainability.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our items parsed out into a Python list - we can go ahead and iterate through each of the items and have whichever OpenAI model you selected create a short marketing email for it!\n",
        "\n",
        "First though, we'll need a system prompt to use!"
      ],
      "metadata": {
        "id": "sLTporSY8QNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = create_prompt(\n",
        "    \"system\",\n",
        "    \"You are a marketing executive. You are proficient at writing short, and snappy marketing emails. The emails should be easy to read, and contain excited and vibrant language.\"\n",
        ")"
      ],
      "metadata": {
        "id": "GIu0qZzJ9dPZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also need a user prompt - we'll have to wrap this in a function so we can call it for each item of the 100 items we created above."
      ],
      "metadata": {
        "id": "5sQH5-BN-DAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_user_prompt(product, description):\n",
        "  user_prompt = create_prompt(\n",
        "      \"user\",\n",
        "      f\"Please create a short marketing email using this product: {product} and this description: {description}\"\n",
        "  )\n",
        "\n",
        "  return user_prompt"
      ],
      "metadata": {
        "id": "pbF9esxS-KK9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're good to start generating our synthetic data! We simply need to iterate through each item - and collate the results into a list of dictionaries!\n",
        "\n",
        "(depending on which model you use, this step might take a long time, and could become expensive!)"
      ],
      "metadata": {
        "id": "tqi_ax8o-iJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai.error import RateLimitError\n",
        "total_token_usage = 0\n",
        "\n",
        "for idx, item in enumerate(products_and_descriptions):\n",
        "  if \"marketing_email\" in item:\n",
        "    continue\n",
        "  print(f\"Working on {idx}\")\n",
        "  user_prompt = generate_user_prompt(item[\"product\"], item[\"description\"])\n",
        "  full_prompt = [system_prompt, user_prompt]\n",
        "  try:\n",
        "    prompt_response = prompt_model(full_prompt)\n",
        "    item[\"marketing_email\"] = prompt_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    total_token_usage += retrieve_token_usage(prompt_response)\n",
        "  except RateLimitError as e:\n",
        "    continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBx7PGNW-raA",
        "outputId": "ae3cc8ac-d1d3-4ead-d105-adf925ecfbf8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on 0\n",
            "Working on 1\n",
            "Working on 2\n",
            "Working on 3\n",
            "Working on 4\n",
            "Working on 5\n",
            "Working on 6\n",
            "Working on 7\n",
            "Working on 8\n",
            "Working on 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products_desc_and_marktng_emails_dataset = [p_d_and_m for p_d_and_m in products_and_descriptions if \"marketing_email\" in p_d_and_m]"
      ],
      "metadata": {
        "id": "4gTKNHr1YxpV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading Dataset to HuggingFace Hub\n",
        "\n",
        "Now that we've created our synthetic dataset - let's push it to the HuggingFace hub!\n",
        "\n",
        "As always, the first task is to get the required dependencies."
      ],
      "metadata": {
        "id": "M2DwQSnfX3YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HrUWPXoU7k",
        "outputId": "3f909c91-609e-4b11-df65-94bcb51ea559"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/302.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can log-in to Hugging Face!\n",
        "\n",
        "Make sure you have a Hugging Face account, and you have set up a read/write token!\n",
        "\n",
        "More info here: https://huggingface.co/docs/hub/security-tokens"
      ],
      "metadata": {
        "id": "AsYiou0LoiyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "i_fslrEAocXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e5d082-80e3-4778-d29b-c52929e87a2d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can load our data into the desired format - and upload it to the hub!"
      ],
      "metadata": {
        "id": "dzcw9DnAo1u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "id": "k-W6NSjrrSt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362f5e45-91b2-42d5-e515-19a208f2ee64"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "319x0ZlJrNrZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = Dataset.from_pandas(pd.DataFrame(data=products_desc_and_marktng_emails_dataset))"
      ],
      "metadata": {
        "id": "ohM2ANNFrYxL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOQgiUutxH8a",
        "outputId": "4ab9ef86-97f3-4f4f-916d-739d09be172c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['product', 'description', 'marketing_email'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_username = \"renatomoulin\"\n",
        "dataset_name = \"fourthbrain_synthetic_marketmail\"\n",
        "\n",
        "hf_dataset.push_to_hub(f\"{hf_username}/{dataset_name}\")"
      ],
      "metadata": {
        "id": "_wRUnFg0xIy5",
        "outputId": "44d770de-0ce8-45b2-a42b-593350b6bb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "6bbf980f01c94ea688acd648f65f1893",
            "ac698fa617a64f8ea319149a004309f8",
            "a76915df2d1b4ea599f2a7011a27b566",
            "20b88c907e0d4687ba7c05879c1166bf",
            "a5f69414a2604fd290c73cbb762e0718",
            "a5340f3e60a449f5b864d76ea8f628db",
            "809bed41aa7b4a0ca751abf4b3d6d947",
            "8dd4a0f8c71b40729773367bf3eed4b6",
            "4bc35f7abf5d4704a78fe6027450c3a0",
            "ea46ac3f8c7d416cbb281efbe99ecec6",
            "09486b1d7e11488485c3fcbdf3d750ae",
            "b92251b4f85b4f1797443b6a6ad700c6",
            "4451989527f84235aa8f5be53a65cfb2",
            "02e3014fe3354216b9da123d80dfd2de",
            "dd896b2cf58b4776b8284758ae58cf10",
            "603dab9c652445e0b916dd36013b4edf",
            "fbf66468ec154ec6afe002843be6de4b",
            "7f71374ada53497585ec35238301f781",
            "bffcd13b8fd94753a8cd25decacc7d45",
            "e196074dd1d54e4c97d2e40e73d020ea",
            "00ea940e065e45d49f196cd10802be2c",
            "c152a44a1c504fcbaf0694fb27a1aa1d"
          ]
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bbf980f01c94ea688acd648f65f1893"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b92251b4f85b4f1797443b6a6ad700c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "And that's it! You just created a synthetic dataset and pushed it to the hub!\n",
        "\n",
        "Next stop? [Modeling!](https://colab.research.google.com/drive/1RfUuzG11Q8AaZuJIHLzXCVC087xoDeSd?usp=sharing)"
      ],
      "metadata": {
        "id": "WNkaJ9m4ZP6B"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "open_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bbf980f01c94ea688acd648f65f1893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac698fa617a64f8ea319149a004309f8",
              "IPY_MODEL_a76915df2d1b4ea599f2a7011a27b566",
              "IPY_MODEL_20b88c907e0d4687ba7c05879c1166bf"
            ],
            "layout": "IPY_MODEL_a5f69414a2604fd290c73cbb762e0718"
          }
        },
        "ac698fa617a64f8ea319149a004309f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5340f3e60a449f5b864d76ea8f628db",
            "placeholder": "​",
            "style": "IPY_MODEL_809bed41aa7b4a0ca751abf4b3d6d947",
            "value": "Pushing dataset shards to the dataset hub: 100%"
          }
        },
        "a76915df2d1b4ea599f2a7011a27b566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd4a0f8c71b40729773367bf3eed4b6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bc35f7abf5d4704a78fe6027450c3a0",
            "value": 1
          }
        },
        "20b88c907e0d4687ba7c05879c1166bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea46ac3f8c7d416cbb281efbe99ecec6",
            "placeholder": "​",
            "style": "IPY_MODEL_09486b1d7e11488485c3fcbdf3d750ae",
            "value": " 1/1 [00:01&lt;00:00,  1.00s/it]"
          }
        },
        "a5f69414a2604fd290c73cbb762e0718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5340f3e60a449f5b864d76ea8f628db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809bed41aa7b4a0ca751abf4b3d6d947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dd4a0f8c71b40729773367bf3eed4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc35f7abf5d4704a78fe6027450c3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea46ac3f8c7d416cbb281efbe99ecec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09486b1d7e11488485c3fcbdf3d750ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92251b4f85b4f1797443b6a6ad700c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4451989527f84235aa8f5be53a65cfb2",
              "IPY_MODEL_02e3014fe3354216b9da123d80dfd2de",
              "IPY_MODEL_dd896b2cf58b4776b8284758ae58cf10"
            ],
            "layout": "IPY_MODEL_603dab9c652445e0b916dd36013b4edf"
          }
        },
        "4451989527f84235aa8f5be53a65cfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf66468ec154ec6afe002843be6de4b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f71374ada53497585ec35238301f781",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "02e3014fe3354216b9da123d80dfd2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bffcd13b8fd94753a8cd25decacc7d45",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e196074dd1d54e4c97d2e40e73d020ea",
            "value": 1
          }
        },
        "dd896b2cf58b4776b8284758ae58cf10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ea940e065e45d49f196cd10802be2c",
            "placeholder": "​",
            "style": "IPY_MODEL_c152a44a1c504fcbaf0694fb27a1aa1d",
            "value": " 1/1 [00:00&lt;00:00, 32.68ba/s]"
          }
        },
        "603dab9c652445e0b916dd36013b4edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf66468ec154ec6afe002843be6de4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f71374ada53497585ec35238301f781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bffcd13b8fd94753a8cd25decacc7d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e196074dd1d54e4c97d2e40e73d020ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00ea940e065e45d49f196cd10802be2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c152a44a1c504fcbaf0694fb27a1aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}